{
  "title": "Decentralized and Self-adaptive Core Maintenance on Temporal Graphs",
  "authors": [
    {
      "firstname": "Davide",
      "surname": "Rucci",
      "email": "davide.rucci@isti.cnr.it"
    },
    {
      "firstname": "Emanuele",
      "surname": "Carlini",
      "email": "emanuele.carlini@isti.cnr.it"
    },
    {
      "firstname": "Patrizio",
      "surname": "Dazzi",
      "email": "patrizio.dazzi@unipi.it"
    },
    {
      "firstname": "Hanna",
      "surname": "Kavalionak",
      "email": "hanna.kavalionak@isti.cnr.it"
    },
    {
      "firstname": "Matteo",
      "surname": "Mordacchini",
      "email": "matteo.mordacchini@iit.cnr.it"
    }
  ],
  "abstract": "Key graph-based problems play a central role in understanding network topology and uncovering patterns of similarity in homogeneous and temporal data. Such patterns can be revealed by analyzing communities formed by nodes, which in turn can be effectively modeled through temporal k-cores. This paper introduces a novel decentralized and incremental algorithm for computing the core decomposition of temporal networks. Decentralized solutions leverage the ability of network nodes to communicate and coordinate locally, addressing complex problems in a scalable, adaptive, and timely manner. By leveraging previously computed coreness values, our approach significantly reduces the activation of nodes and the volume of message exchanges when the network changes over time. This enables scalability with only a minimal trade-off in precision. Experimental evaluations on large real-world networks under varying levels of dynamism demonstrate the efficiency of our solution compared to a state-of-the-art approach, particularly in terms of active nodes, communication overhead, and convergence speed.",
  "sections": [
    {
      "title": "Introduction",
      "paragraphs": [
        "Graphs are a fundamental data model in computer science, capable of representing virtually any relationship among a set of entities. Their structure allows many key problems to be addressed in a graph-based form, such as detecting connected components [13,20], computing node centrality [2], solving vertex cover problems [4,26], and performing core decomposition [3,16,18]. These problems are closely related because their focus is on understanding the underlying organization of the graph, particularly in identifying communities-subsets of nodes that are densely connected internally but sparsely connected to the rest of the network. The detection and analysis of such community structures are crucial in many real-world applications, as proven by the many research efforts in the field. However, as graph data becomes increasingly large and available, traditional centralized algorithms face significant limitations in terms of scalability, latency, and resource consumption. In response, decentralized computing models have emerged as a viable alternative. In fact, by distributing the computational workload across the network, decentralized systems enhance scalability and enable more efficient processing of large-scale graphs [21,24].",
        "A further layer of complexity arises when considering dynamic or temporal graphs, where nodes and edges change over time. This temporal dimension introduces new challenges for graph analysis, particularly for centralized systems that rely on global knowledge and batch processing. Centralized methods often struggle to accommodate rapid or frequent changes, resulting in inefficiencies and delayed responses. In contrast, decentralized approaches can naturally adapt to dynamic environments by leveraging localized communication and incremental updates. This adaptability allows nodes to recompute relevant metrics in response to changes without restarting from scratch, thereby maintaining efficiency in continuously evolving networks.",
        "Within this context, this paper focuses on the decentralized coreness (or core number) computation and its evolution over time. Since their introduction in the 1970s [18], k-cores and their analysis have gained increasing popularity. Knowing a node's coreness -i.e., the largest k such that it belongs to the k-core -offers valuable insight into the network structure, supporting tasks like community detection and node ranking [6,8,9,14]. Coreness reflects how densely connected a node is within its local neighborhood and indicates membership in cohesive subgraphs, making it a useful indicator of structural relevance.",
        "In social networks, the coreness helps identify influential users that facilitate information spread [6]; it is also applied, among other uses, to anomaly detection [19] and routing optimization in blockchain networks [27]. Tracking coreness over time further aids in understanding the evolution of core structures and identifying stable, central components [5]. While some decentralized algorithms have been proposed for static k-core computation (e.g., Montresor et al. [16]), they do not handle temporal changes natively. Conversely, several centralized approaches exist for temporal k-core decomposition [7], but they lack the scalability of decentralized methods.",
        "We introduce a decentralized, iterative, message-passing, and incremental algorithm for computing the k-core composition of temporal graphs. Our approach leverages previously computed coreness values to reduce the number of active nodes and exchanged messages, accepting a slight trade-off in accuracy. In fact, our experiments on large, real-world graphs show a reduction of 50%-90% in the number of total messages exchanged during the execution of our algorithm with respect to a state-of-the-art competitor.",
        "To summarize, the main contributions of this paper are:",
        "-A novel decentralized algorithm for coreness computation in temporal graphs; -Simulation over large, heterogeneous real-world networks with varying temporal parameters; -A comparative evaluation with a state-of-the-art approach, analyzing active nodes, message counts, and convergence;",
        "-Public release of the code to foster reproducibility and comparison.",
        "The remainder of this paper is structured as follows. Section 2 reviews the related work. Section 3 outlines the algorithm, notation, and definitions. Section 4 details the experimental setup and presents the main results. Finally, Section 5 concludes with a summary of key contributions and future research directions."
      ],
      "subsections": []
    },
    {
      "title": "Related Work",
      "paragraphs": [
        "Several studies have explored core decomposition in temporal networks, developing various definitions and centralized algorithms [15]. Yang et al. [25] introduce the Temporal k-core Query problem and propose the Temporal Core Decomposition algorithm, which efficiently computes k-cores across time intervals while minimizing redundant calculations. Li et al. [11] define a k-core model that ensures stability over time, using graph reduction techniques coupled with a branch-and-bound approach. Wu et al. [23] present a temporal core decomposition method that incorporates edge-based constraints to identify frequently interacting subgraphs.",
        "Galimberti et al. [7] propose a method for analyzing temporal networks using temporal core decomposition. In their framework, each core is characterized by two parameters: the minimum degree and the span, which indicates the time interval over which the core persists. They develop efficient algorithms to compute these span-cores and demonstrate their effectiveness in real-world applications, such as analyzing contact networks and studying the evolution of social interactions. Although the approach of Galimberti et al. aligns with our philosophy of intersection-based decomposition (see Section 3.1), their definition of temporal core identification does not match our definition, since they have tailored it to compute a slightly different concept. A recent work by Conte et al. [5] offers a comprehensive summary of the various definitions of temporal k core that have been proposed in the above articles, highlighting the key differences and comparing the results that can be obtained by exploiting those definitions. This work also drives our algorithm design later in Section 3.",
        "These contributions mostly focus on centralized algorithms for the temporal core decomposition task, assuming that a single computational entity processes the entire graph. Our work shifts the focus to decentralized solutions, aiming to distribute the computation across multiple nodes rather than relying on a central processing unit.",
        "An influential solution to decentralize the computation of the k-core for static graphs was introduced by Montresor et al. [16]. They proposed a messageexchange algorithm based on the locality property of the k-core decomposition, which states that the coreness of a node is the highest number k for which the node has at least k neighbors in a k-core or higher. While their algorithm offers a fast convergence rate, it cannot be directly translated into a temporal scenario, as it would require recomputing everything from scratch each time the graph changes.",
        "Aridhi et al. [1] propose distributed algorithms for efficient core decomposition and maintenance in large-scale dynamic graphs. Their approach addresses the computational challenges of massive and evolving graph structures by incrementally updating the core decomposition as the graph changes. However, such a solution relies on a hybrid model with a master node that orchestrates the update process, while different worker nodes handle the partitions. In contrast, our work proposes a fully decentralized solution, focusing on reducing the number of activated nodes and minimizing message exchanges, further optimizing performance in dynamic graph settings. Weng et al. [22] leverage a Pregel-like graph computing framework and focus on efficient algorithms to update core decompositions as the graph evolves. Their proposed methods aim to enhance the performance and scalability of core maintenance tasks within distributed computing environments, addressing challenges in large-scale graph processing. Liu and Zhang [12] introduce core maintenance algorithms for edge insertion and deletion, which are validated through experiments on real-world graphs, in dynamic, edge-weighted graphs. This is different from our approach, which is focused on unweighted temporal graphs. Yu et al. [28] present efficient algorithms for maintaining core numbers in dynamic graphs. They introduce the concept of a superior edge set to handle multiple edge insertions and deletions simultaneously, reducing redundant vertex visits. Their incremental and decremental core maintenance algorithms support parallel implementations, but remain centralized and are primarily designed for dynamic graphs, unlike our approach, which emphasizes decentralized solutions on temporal graphs.",
        "In summary, while these studies offer valuable contributions to the core decomposition and maintenance task in dynamic and temporal networks, they predominantly rely on centralized or semi-centralized methods. In contrast, our approach is decentralized, focusing on minimizing the number of activated nodes and reducing redundant message exchanges. By distributing the computational load across multiple nodes and optimizing communication, we aim to achieve greater efficiency and scalability in dynamic environments, without depending on a central processing entity. Another key distinction lies in the concepts of temporal and dynamic graphs. Temporal graphs are inherently dynamic, but organized differently. Firstly, temporal graphs typically allow for the reconstruction of changes over time by providing snapshot-or epoch-based organization. On the other hand, dynamic graphs are usually designed to react to instant changes, also providing algorithmic methods to update necessary data structures whenever a single edge or node is inserted or deleted. Furthermore, in temporal graph algorithms, we can decide how significant an interaction is within a specific time interval. For example, we can prioritize a connection that lasts longer over many connections that exist only for a single snapshot."
      ],
      "subsections": []
    },
    {
      "title": "Algorithm",
      "paragraphs": [
        "This Section outlines our decentralized approach for determining the coreness of nodes in a temporal graph. We begin with fundamental notation and definitions that will be referenced throughout the paper, followed by a presentation and analysis of our algorithm's pseudocode.",
        "Algorithm 1: Distributed Algorithm for k-core computation in a temporal graph G τ , run by each node u ∈ V .",
        "1 on initialization do // when a node joins Gτ"
      ],
      "subsections": []
    },
    {
      "title": "Notation and Definitions",
      "paragraphs": [
        "Formally, we define a temporal graph G τ as a pair of sets of vertices and temporal edges (V, E τ ), where τ ∈ N is called the lifespan of G, and the set of edges of G τ is defined as",
        "where t is the timestamp of an edge. If we consider only the edges of E τ with a fixed value for 1 ≤ t ≤ τ , we obtain the static graph G t = (V, E t ) that is called snapshot or epoch of G at time t. A static k-core K is defined as the inclusion-maximal subset of vertices K ⊆ V such that every vertex of K has degree at least k in the vertex-induced subgraph",
        "The maximum k for which a node v belongs to the k-core of a graph is called coreness (also core number in the literature [18]) of v. The main issue to be addressed when translating the concept of k-cores from static to temporal graphs is the selection of the most appropriate aggregation function, i.e., which edges are to be considered for the computation of cores for a given time interval. A recent study by Conte et al. [5], empirically shows that there exists no one-for-all solution to this problem; instead, a set of graphs may be analyzed with a set of distinct aggregation functions af :",
        "tell us which edges to consider as present in the graph for that interval. We informally summarize here the possible functions that can be adopted, referring the reader to the paper by Conte et al. [5] for a more formal overview of those and when to use which. We will denote this function by ∪ h later in the paper.",
        "We denote the neighborhood at time t of v ∈ V as N t (v), or just N (v) whenever t is clear from the context. Similarly, the degree at time",
        ", omitting the t when clear from the context. A key question to address each time we use intervals on temporal graphs is: how do we choose both the extremes and the length of intervals? Our answer is to introduce a parameter, called memory size, to serve as the length of every interval; then, we use a sliding window approach, spanning the entire lifetime of the graph. For example, setting the memory size to 5 implicitly allows nodes to \"recall\" the last 5 snapshots in their neighborhood. Then, we use the edge aggregation function to decide which neighbors are actually part of the graph in the interval."
      ],
      "subsections": []
    },
    {
      "title": "Our Decentralized Algorithm",
      "paragraphs": [
        "Our strategy is formalized in the pseudocode of Algorithm 1. It is a messageexchange approach in which the computation is organized in rounds or iterations.",
        "For each iteration, the nodes communicate estimates of their coreness value to their neighbors, which, in turn, adjust theirs based on what they received. We note that Algorithm 1 is fully decentralized and can run for an indefinite period of time, as it can adapt to every change in the graph. There are three main parts into which we can subdivide the algorithm that runs from every node present in the graph: initialization, new epoch, and reception of a message, and we analyze them separately.",
        "Initialization. When a new node entity is generated, the initial step is performed: it assigns its coreness estimate to its degree, as this is the sole information available at creation, sets its neighbors' estimates to infinity since they are unknown, and then communicates its degree to its neighbors.",
        "Epoch Change. When the event of a new epoch in the temporal graph occurs, there are three possibilities for each node: (a) the node gains a new neighbor, (b) the node does not gain any new neighbor but loses at least one neighbor instead, or (c) the neighborhood of the node is not affected. Only the first two possibilities trigger a reaction of the node:",
        "(a) the node acquires at least one new neighbor, prompting it to update its coreness estimate to reflect its new degree, as this ensures accuracy. (b) the node experiences a loss of one or more neighbors without gaining any new ones; under these circumstances, the node attempts to recalculate its coreness using knowledge of its remaining neighbors. This capability is crucial to the algorithm, allowing us to use preexisting graph information and bypass the need to transmit potentially unnecessary messages. This approach also helps in identifying whether the departure of neighbors affects coreness, without the need to wait for a complete message cycle.",
        "Note that case (a) takes precedence over case (b), since the simultaneous occurrence of these events results in at least one infinite value in the node's estimate table, potentially raising its coreness value. Therefore, we opt for a cautious strategy by resetting the coreness to the degree.",
        "Message received. The last event that we consider is the reception of a message from a neighbor, which triggers an update in the table of estimates of the recipient and possibly a change in the coreness value. The main aspect is the check on line 18, which postpones sending an update message to the following iteration if our coreness estimate is less than before. This helps reduce potential errors originating from delayed change propagation across the graph, since a neighbor might experience an increase in its coreness when a new node joins its neighborhood. Indeed, it requires two iterations for a node to detect a change in the coreness of its neighbors if those neighbors have acquired new connections within the same epoch. We will address this issue later. connecting with nodes A and C, while the link between A and C disappears. Furthermore, three new neighbors of B appear, each with a degree and coreness of 3. For the sake of clarity and simplicity, in this example we ignore the updates sent by the new neighbors of B, and show only the local effects on the initial nodes. Since each node has acquired at least one new neighbor, they all revert their coreness to match their degree and adjust the table entry for any new neighbors to infinity. In iteration # 1, all nodes that received a new neighbor (and thus have their changed variable now set to true) send a new message with their core estimate (set to their degree) to their neighbors. Nodes A, C, and D send a value of 2, while B sends a value of 5. As a result, all nodes get messages and revise their coreness. Nodes A, C, and D have unchanged coreness and therefore cease sending messages. Node B alters its coreness to 3, down from 5. Consequently, it delays messaging its neighbors for one iteration to account for possible propagation delays due to changes occurring in its two-hop neighbors. The message is finally sent at Iteration #3. Since this new information received does not change the coreness of any neighbors, the process stops."
      ],
      "subsections": []
    },
    {
      "title": "Example",
      "paragraphs": [],
      "subsections": []
    },
    {
      "title": "Efficiency/errors trade off",
      "paragraphs": [
        "Since Algorithm 1 is the result of empirical and iterative refinements, its strategy may lead to errors in the computed coreness for some nodes. This primarily results from each graph node consistently treating the estimates it receives from its neighbors as valid, rather than resetting them to infinity with each epoch change. Thus, while executing the function on line 26, a node's coreness may abruptly shift from a high value, such as its degree, to a minimal coreness value, bypassing potential intermediate values. Generally, this isn't a problem since the coreness can vary; however, this sometimes causes nodes to compute incorrect values. Our empirical analysis revealed that this phenomenon typically occurs when new nodes enter the graph. Neighbors, located two hops from these new nodes, tend to calculate an incorrect value compared based on the competitor we considered, which also serves as the ground truth for coreness values. This explains why we implemented a delay before dispatching updates when a node calculates a coreness lower than its prior value: this allows the node to potentially determine a new and accurate coreness in the next cycle if it gets additional updates from its neighbors. Adopting a method that allows for some errors involves a compromise between strategy efficiency and error count: indeed, to completely eliminate errors, we would need to reset all estimates whenever an epoch changes, requiring each node to send at least one message for every epoch in the graph. Conversely, by extensively reusing our existing estimates, we risk calculating an incorrect value, but gain a notably faster algorithm.",
        "As we verified (see Section 4) that the offset of the errors produced by Algorithm 1 is always in the range ±1 and that, most importantly, it affects a very small portion of nodes in the whole graph, we accept to have some small errors to get a big saving in the efficiency metrics in return."
      ],
      "subsections": []
    },
    {
      "title": "Experimental evaluation",
      "paragraphs": [
        "This section provides an overview of our comprehensive experimental phase, describes the algorithm selected as the competitor for validating our analysis, and presents a discussion of the key results achieved."
      ],
      "subsections": []
    },
    {
      "title": "Competitor",
      "paragraphs": [
        "To compare and verify our results, we take advantage of a revised version of the algorithm originally proposed by Montresor et al. [16], which was designed for static graphs. The structure of this algorithm mirrors that of Algorithm 1, meaning each node monitors updates to its own coreness estimate and maintains an estimate of the coreness of its neighboring nodes. Montresor et al. provide a formal proof demonstrating that their method consistently converges to the accurate coreness value for every node in a graph [16]. This algorithm can be modified to accommodate the temporal scenario by recalculating completely whenever there is an epoch transition: each node discards all estimates about its neighbors and assigns its coreness equal to its degree. We use this adaptation to compute ground truth values for the coreness of nodes, and to show the amount of savings we can achieve by adopting our fine-tuned strategy instead of a direct translation of an existing algorithm to the temporal context."
      ],
      "subsections": []
    },
    {
      "title": "Experimental Setup and Dataset",
      "paragraphs": [
        "We implemented both algorithms (Algorithm 1 and the aforementioned competitor by Montresor et al. [16]) in the Rust programming language, and carried out our experiments on the following architecture: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz, 8 physical cores, 16 logical cores with 64 GB of RAM, and 16 MB of shared L3 cache. Our code is publicly available on GitHub4 . To simulate the distributed environment, we used two queues for gathering nodes and messages sent by the nodes, to dispatch them to the appropriate recipients. Initially, we gather the indices of nodes required to transmit a message as a vector. Subsequently, each node sends its message to a separate message queue, and ultimately, each message is sent to the appropriate recipient for processing. A node that receives a message and needs to send a new one will postpone its transmission until the next iteration of the algorithm. To streamline deployment and evaluation, our implementation includes a central entity called the Graph that verifies the convergence of the algorithm and the coreness computation of each node. However, we remark that Algorithm 1 is entirely decentralized and works correctly without an orchestrator.",
        "We run the experiments on a dataset of real-world temporal graphs obtained from the SNAP Repository [10] and Network Repository [17]. The dataset, summarized in in Table 1, offers a varying level of dynamism, i.e. how much and how fast a graph changes over time, that can be noticed by looking at the plots in Figs. 2(d) and 3(d), which show how much a graph changes between two consecutive epochs. For each graph, we only give the maximum number of distinct nodes that have been active at least once throughout the lifespan of the graph. For any given epoch, the number of nodes that are part of the graph, i.e., that have at least one incident edge, is upper-bounded by this value. The number of edges reported follows a similar rationale, representing the total count of edges present in the graph during at least one epoch. We manually chose the epoch length for each graph by grouping edges according to their timestamp, in a way such that each epoch is sufficiently populated with nodes and edges so that the results obtained are not trivial (e.g. nodes are not isolated and there is enough change in active edges for any two consecutive epochs). We run both algorithms on the whole dataset, collecting the following metrics:",
        "-Activated nodes: nodes that sent at least one message during the execution of the algorithms. -Number of iterations: number of iterations of the main loop of the algorithms needed at a certain epoch to terminate their execution. -Number of messages: the number of messages sent by all nodes for each iteration of the algorithms. -Errors: number of nodes that computed a different coreness value in Algorithm 1 with respect to the ones computed by our competitor.",
        "Different values for the memory size of each node were tested, spanning from a minimal size (1) to a larger size (10). Given space constraints, we present results solely for a memory size of 5, which represents a compromise between the extremes. Moreover, as we pointed out in Section 1, we tested different edge aggregation functions, namely intersection, union and union-2 (or half ), i.e., every edge must appear at least half of the memory size times (for a memory size of 5, half corresponds to 2, = ⌊5/2⌋)."
      ],
      "subsections": []
    },
    {
      "title": "Results and Discussion",
      "paragraphs": [
        "Table 2 summarizes the results we obtained for Algorithm 1, compared to our competitor, highlighting the ratio between the two. We can immediately notice that the ratio of both the activated nodes and the total messages is always well below 1, showing a big savings on these two critical measures. Another thing we notice is the average number of iterations performed by Algorithm 1 against the competitor: this is due to our strategy of delaying the action of sending an update to the next iteration, to reduce the error rate. Although this may appear as a step back with respect to the Montresor et al. strategy [16], it is important to note that despite this, the number of activated nodes and the total number of messages exchanged do not increase. Thus, the savings in resources are still consistent even if the number of iterations to reach convergence increases. Moreover, in our experiments, this number never exceeded twice the amount of the competitor. Fig. 2(c) shows the values of the number of iterations for the AS-733 dataset, where we can further verify this statement. We now turn to the error rate. Recall that we count one error for each node that, at the end of an execution of Algorithm 1, has a coreness value different from the one computed by our competitor algorithm. Table 2 shows the average number of errors per epoch, both in absolute and relative terms, relative to the number of nodes in the graph. We consistently obtained less than 1% of errors in every configuration for every dataset, proving we can achieve a significant speedup without losing too much accuracy. Additionally, in our experiments, we verified that all errors are always ±1 with respect to the correct value of coreness computed by our competitor. It is interesting to see how the algorithm reacts to different epoch lengths when the aggregation function and memory size are fixed. Indeed, there is basically no difference between the results for the Reddit dataset when the epoch length is enlarged to 14 days instead of 7. On the other hand, if we change the function and keep the same epoch length, things change drastically (e.g. Reddit dataset with intersection).",
        "Fig. 2 and Fig. 3 go more in depth on the statistics we gathered for two specific datasets and configurations, namely AS-733 with intersection as the edge aggregation function, and sx-mathoverflow with union. In particular, we plotted the percentage of activated nodes for our algorithm and our competitor by Montresor et al. [16], together with two measures of how much the corresponding graph has changed with respect to the previous epoch. We first computed the Jaccard similarity between the edge list of any two consecutive epochs and subtracted it from 1 to obtain a measure of how much the graph has changed from the perspective of the edges. This number is trivially equal to 1 for the first epoch of every graph.",
        "We also calculated the number of nodes that changed their coreness value with respect to the previous epoch: this number also includes those nodes who became isolated (i.e. have coreness equal to 0 or, equivalently, are not part of the graph anymore) on an epoch, hence the spikes in Fig. 2. Correctly, the number of activated nodes stays low even in the presence of such spikes, because the isolated nodes do not send any message, therefore, they cannot become active. On the other hand, we see that the trend of activated nodes in AS-733 (Fig. 2) follows the trend of how much the edges in the graph change, as high values of dissimilarity (pink line) correspond to higher values of activated nodes by Algorithm 1. This holds for our competitor too, but that algorithm is blind to changes in the graph 5 , as it recomputes everything from scratch each time."
      ],
      "subsections": []
    },
    {
      "title": "Takeaways",
      "paragraphs": [
        "The experimental results suggest two main conclusions about our approach: 5 For the AS-733 dataset, there is a significant change in the graph in epochs 54-59. This is intrinsic to the dataset itself and not caused by our implementation. The possible reasons behind this sudden change are discussed in [5].",
        "1. Algorithm 1 significantly reduces the number of exchanged messages compared to the competitor solution. This translates into lower computational demand and enables the analysis of larger graphs than previously feasible. 2. Although our algorithm requires slightly more iterations to converge, it maintains a low level of node activation throughout. As a result, the majority of nodes remain idle during execution, minimizing overall resource consumption and increasing scalability despite the increased number of rounds."
      ],
      "subsections": []
    },
    {
      "title": "Conclusions",
      "paragraphs": [
        "We presented a new decentralized algorithm for the maintenance of core decomposition in large temporal graphs, an important task for community detection and analysis in nowadays networks. We conducted an extensive experimental phase, demonstrating significant performance improvements compared to the direct translation of an existing algorithm [16] into the temporal scenario. These improvements are measured in terms of the total messages exchanged during the algorithm's execution and the number of graph nodes that send at least one message. While this strategy sometimes leads to small errors in the computed coreness values, we showed that these errors are (a) always at ±1 unit from the true value, and (b) extremely infrequent in our real-world dataset. Our findings pave the way for future work on this algorithm, to ensure its correctness in all cases while maintaining the same desirable performance."
      ],
      "subsections": []
    }
  ],
  "body_paragraphs": [
    "Graphs are a fundamental data model in computer science, capable of representing virtually any relationship among a set of entities. Their structure allows many key problems to be addressed in a graph-based form, such as detecting connected components [13,20], computing node centrality [2], solving vertex cover problems [4,26], and performing core decomposition [3,16,18]. These problems are closely related because their focus is on understanding the underlying organization of the graph, particularly in identifying communities-subsets of nodes that are densely connected internally but sparsely connected to the rest of the network. The detection and analysis of such community structures are crucial in many real-world applications, as proven by the many research efforts in the field. However, as graph data becomes increasingly large and available, traditional centralized algorithms face significant limitations in terms of scalability, latency, and resource consumption. In response, decentralized computing models have emerged as a viable alternative. In fact, by distributing the computational workload across the network, decentralized systems enhance scalability and enable more efficient processing of large-scale graphs [21,24].",
    "A further layer of complexity arises when considering dynamic or temporal graphs, where nodes and edges change over time. This temporal dimension introduces new challenges for graph analysis, particularly for centralized systems that rely on global knowledge and batch processing. Centralized methods often struggle to accommodate rapid or frequent changes, resulting in inefficiencies and delayed responses. In contrast, decentralized approaches can naturally adapt to dynamic environments by leveraging localized communication and incremental updates. This adaptability allows nodes to recompute relevant metrics in response to changes without restarting from scratch, thereby maintaining efficiency in continuously evolving networks.",
    "Within this context, this paper focuses on the decentralized coreness (or core number) computation and its evolution over time. Since their introduction in the 1970s [18], k-cores and their analysis have gained increasing popularity. Knowing a node's coreness -i.e., the largest k such that it belongs to the k-core -offers valuable insight into the network structure, supporting tasks like community detection and node ranking [6,8,9,14]. Coreness reflects how densely connected a node is within its local neighborhood and indicates membership in cohesive subgraphs, making it a useful indicator of structural relevance.",
    "In social networks, the coreness helps identify influential users that facilitate information spread [6]; it is also applied, among other uses, to anomaly detection [19] and routing optimization in blockchain networks [27]. Tracking coreness over time further aids in understanding the evolution of core structures and identifying stable, central components [5]. While some decentralized algorithms have been proposed for static k-core computation (e.g., Montresor et al. [16]), they do not handle temporal changes natively. Conversely, several centralized approaches exist for temporal k-core decomposition [7], but they lack the scalability of decentralized methods.",
    "We introduce a decentralized, iterative, message-passing, and incremental algorithm for computing the k-core composition of temporal graphs. Our approach leverages previously computed coreness values to reduce the number of active nodes and exchanged messages, accepting a slight trade-off in accuracy. In fact, our experiments on large, real-world graphs show a reduction of 50%-90% in the number of total messages exchanged during the execution of our algorithm with respect to a state-of-the-art competitor.",
    "To summarize, the main contributions of this paper are:",
    "-A novel decentralized algorithm for coreness computation in temporal graphs; -Simulation over large, heterogeneous real-world networks with varying temporal parameters; -A comparative evaluation with a state-of-the-art approach, analyzing active nodes, message counts, and convergence;",
    "-Public release of the code to foster reproducibility and comparison.",
    "The remainder of this paper is structured as follows. Section 2 reviews the related work. Section 3 outlines the algorithm, notation, and definitions. Section 4 details the experimental setup and presents the main results. Finally, Section 5 concludes with a summary of key contributions and future research directions.",
    "Several studies have explored core decomposition in temporal networks, developing various definitions and centralized algorithms [15]. Yang et al. [25] introduce the Temporal k-core Query problem and propose the Temporal Core Decomposition algorithm, which efficiently computes k-cores across time intervals while minimizing redundant calculations. Li et al. [11] define a k-core model that ensures stability over time, using graph reduction techniques coupled with a branch-and-bound approach. Wu et al. [23] present a temporal core decomposition method that incorporates edge-based constraints to identify frequently interacting subgraphs.",
    "Galimberti et al. [7] propose a method for analyzing temporal networks using temporal core decomposition. In their framework, each core is characterized by two parameters: the minimum degree and the span, which indicates the time interval over which the core persists. They develop efficient algorithms to compute these span-cores and demonstrate their effectiveness in real-world applications, such as analyzing contact networks and studying the evolution of social interactions. Although the approach of Galimberti et al. aligns with our philosophy of intersection-based decomposition (see Section 3.1), their definition of temporal core identification does not match our definition, since they have tailored it to compute a slightly different concept. A recent work by Conte et al. [5] offers a comprehensive summary of the various definitions of temporal k core that have been proposed in the above articles, highlighting the key differences and comparing the results that can be obtained by exploiting those definitions. This work also drives our algorithm design later in Section 3.",
    "These contributions mostly focus on centralized algorithms for the temporal core decomposition task, assuming that a single computational entity processes the entire graph. Our work shifts the focus to decentralized solutions, aiming to distribute the computation across multiple nodes rather than relying on a central processing unit.",
    "An influential solution to decentralize the computation of the k-core for static graphs was introduced by Montresor et al. [16]. They proposed a messageexchange algorithm based on the locality property of the k-core decomposition, which states that the coreness of a node is the highest number k for which the node has at least k neighbors in a k-core or higher. While their algorithm offers a fast convergence rate, it cannot be directly translated into a temporal scenario, as it would require recomputing everything from scratch each time the graph changes.",
    "Aridhi et al. [1] propose distributed algorithms for efficient core decomposition and maintenance in large-scale dynamic graphs. Their approach addresses the computational challenges of massive and evolving graph structures by incrementally updating the core decomposition as the graph changes. However, such a solution relies on a hybrid model with a master node that orchestrates the update process, while different worker nodes handle the partitions. In contrast, our work proposes a fully decentralized solution, focusing on reducing the number of activated nodes and minimizing message exchanges, further optimizing performance in dynamic graph settings. Weng et al. [22] leverage a Pregel-like graph computing framework and focus on efficient algorithms to update core decompositions as the graph evolves. Their proposed methods aim to enhance the performance and scalability of core maintenance tasks within distributed computing environments, addressing challenges in large-scale graph processing. Liu and Zhang [12] introduce core maintenance algorithms for edge insertion and deletion, which are validated through experiments on real-world graphs, in dynamic, edge-weighted graphs. This is different from our approach, which is focused on unweighted temporal graphs. Yu et al. [28] present efficient algorithms for maintaining core numbers in dynamic graphs. They introduce the concept of a superior edge set to handle multiple edge insertions and deletions simultaneously, reducing redundant vertex visits. Their incremental and decremental core maintenance algorithms support parallel implementations, but remain centralized and are primarily designed for dynamic graphs, unlike our approach, which emphasizes decentralized solutions on temporal graphs.",
    "In summary, while these studies offer valuable contributions to the core decomposition and maintenance task in dynamic and temporal networks, they predominantly rely on centralized or semi-centralized methods. In contrast, our approach is decentralized, focusing on minimizing the number of activated nodes and reducing redundant message exchanges. By distributing the computational load across multiple nodes and optimizing communication, we aim to achieve greater efficiency and scalability in dynamic environments, without depending on a central processing entity. Another key distinction lies in the concepts of temporal and dynamic graphs. Temporal graphs are inherently dynamic, but organized differently. Firstly, temporal graphs typically allow for the reconstruction of changes over time by providing snapshot-or epoch-based organization. On the other hand, dynamic graphs are usually designed to react to instant changes, also providing algorithmic methods to update necessary data structures whenever a single edge or node is inserted or deleted. Furthermore, in temporal graph algorithms, we can decide how significant an interaction is within a specific time interval. For example, we can prioritize a connection that lasts longer over many connections that exist only for a single snapshot.",
    "This Section outlines our decentralized approach for determining the coreness of nodes in a temporal graph. We begin with fundamental notation and definitions that will be referenced throughout the paper, followed by a presentation and analysis of our algorithm's pseudocode.",
    "Algorithm 1: Distributed Algorithm for k-core computation in a temporal graph G τ , run by each node u ∈ V .",
    "1 on initialization do // when a node joins Gτ",
    "Formally, we define a temporal graph G τ as a pair of sets of vertices and temporal edges (V, E τ ), where τ ∈ N is called the lifespan of G, and the set of edges of G τ is defined as",
    "where t is the timestamp of an edge. If we consider only the edges of E τ with a fixed value for 1 ≤ t ≤ τ , we obtain the static graph G t = (V, E t ) that is called snapshot or epoch of G at time t. A static k-core K is defined as the inclusion-maximal subset of vertices K ⊆ V such that every vertex of K has degree at least k in the vertex-induced subgraph",
    "The maximum k for which a node v belongs to the k-core of a graph is called coreness (also core number in the literature [18]) of v. The main issue to be addressed when translating the concept of k-cores from static to temporal graphs is the selection of the most appropriate aggregation function, i.e., which edges are to be considered for the computation of cores for a given time interval. A recent study by Conte et al. [5], empirically shows that there exists no one-for-all solution to this problem; instead, a set of graphs may be analyzed with a set of distinct aggregation functions af :",
    "tell us which edges to consider as present in the graph for that interval. We informally summarize here the possible functions that can be adopted, referring the reader to the paper by Conte et al. [5] for a more formal overview of those and when to use which. We will denote this function by ∪ h later in the paper.",
    "We denote the neighborhood at time t of v ∈ V as N t (v), or just N (v) whenever t is clear from the context. Similarly, the degree at time",
    ", omitting the t when clear from the context. A key question to address each time we use intervals on temporal graphs is: how do we choose both the extremes and the length of intervals? Our answer is to introduce a parameter, called memory size, to serve as the length of every interval; then, we use a sliding window approach, spanning the entire lifetime of the graph. For example, setting the memory size to 5 implicitly allows nodes to \"recall\" the last 5 snapshots in their neighborhood. Then, we use the edge aggregation function to decide which neighbors are actually part of the graph in the interval.",
    "Our strategy is formalized in the pseudocode of Algorithm 1. It is a messageexchange approach in which the computation is organized in rounds or iterations.",
    "For each iteration, the nodes communicate estimates of their coreness value to their neighbors, which, in turn, adjust theirs based on what they received. We note that Algorithm 1 is fully decentralized and can run for an indefinite period of time, as it can adapt to every change in the graph. There are three main parts into which we can subdivide the algorithm that runs from every node present in the graph: initialization, new epoch, and reception of a message, and we analyze them separately.",
    "Initialization. When a new node entity is generated, the initial step is performed: it assigns its coreness estimate to its degree, as this is the sole information available at creation, sets its neighbors' estimates to infinity since they are unknown, and then communicates its degree to its neighbors.",
    "Epoch Change. When the event of a new epoch in the temporal graph occurs, there are three possibilities for each node: (a) the node gains a new neighbor, (b) the node does not gain any new neighbor but loses at least one neighbor instead, or (c) the neighborhood of the node is not affected. Only the first two possibilities trigger a reaction of the node:",
    "(a) the node acquires at least one new neighbor, prompting it to update its coreness estimate to reflect its new degree, as this ensures accuracy. (b) the node experiences a loss of one or more neighbors without gaining any new ones; under these circumstances, the node attempts to recalculate its coreness using knowledge of its remaining neighbors. This capability is crucial to the algorithm, allowing us to use preexisting graph information and bypass the need to transmit potentially unnecessary messages. This approach also helps in identifying whether the departure of neighbors affects coreness, without the need to wait for a complete message cycle.",
    "Note that case (a) takes precedence over case (b), since the simultaneous occurrence of these events results in at least one infinite value in the node's estimate table, potentially raising its coreness value. Therefore, we opt for a cautious strategy by resetting the coreness to the degree.",
    "Message received. The last event that we consider is the reception of a message from a neighbor, which triggers an update in the table of estimates of the recipient and possibly a change in the coreness value. The main aspect is the check on line 18, which postpones sending an update message to the following iteration if our coreness estimate is less than before. This helps reduce potential errors originating from delayed change propagation across the graph, since a neighbor might experience an increase in its coreness when a new node joins its neighborhood. Indeed, it requires two iterations for a node to detect a change in the coreness of its neighbors if those neighbors have acquired new connections within the same epoch. We will address this issue later. connecting with nodes A and C, while the link between A and C disappears. Furthermore, three new neighbors of B appear, each with a degree and coreness of 3. For the sake of clarity and simplicity, in this example we ignore the updates sent by the new neighbors of B, and show only the local effects on the initial nodes. Since each node has acquired at least one new neighbor, they all revert their coreness to match their degree and adjust the table entry for any new neighbors to infinity. In iteration # 1, all nodes that received a new neighbor (and thus have their changed variable now set to true) send a new message with their core estimate (set to their degree) to their neighbors. Nodes A, C, and D send a value of 2, while B sends a value of 5. As a result, all nodes get messages and revise their coreness. Nodes A, C, and D have unchanged coreness and therefore cease sending messages. Node B alters its coreness to 3, down from 5. Consequently, it delays messaging its neighbors for one iteration to account for possible propagation delays due to changes occurring in its two-hop neighbors. The message is finally sent at Iteration #3. Since this new information received does not change the coreness of any neighbors, the process stops.",
    "Since Algorithm 1 is the result of empirical and iterative refinements, its strategy may lead to errors in the computed coreness for some nodes. This primarily results from each graph node consistently treating the estimates it receives from its neighbors as valid, rather than resetting them to infinity with each epoch change. Thus, while executing the function on line 26, a node's coreness may abruptly shift from a high value, such as its degree, to a minimal coreness value, bypassing potential intermediate values. Generally, this isn't a problem since the coreness can vary; however, this sometimes causes nodes to compute incorrect values. Our empirical analysis revealed that this phenomenon typically occurs when new nodes enter the graph. Neighbors, located two hops from these new nodes, tend to calculate an incorrect value compared based on the competitor we considered, which also serves as the ground truth for coreness values. This explains why we implemented a delay before dispatching updates when a node calculates a coreness lower than its prior value: this allows the node to potentially determine a new and accurate coreness in the next cycle if it gets additional updates from its neighbors. Adopting a method that allows for some errors involves a compromise between strategy efficiency and error count: indeed, to completely eliminate errors, we would need to reset all estimates whenever an epoch changes, requiring each node to send at least one message for every epoch in the graph. Conversely, by extensively reusing our existing estimates, we risk calculating an incorrect value, but gain a notably faster algorithm.",
    "As we verified (see Section 4) that the offset of the errors produced by Algorithm 1 is always in the range ±1 and that, most importantly, it affects a very small portion of nodes in the whole graph, we accept to have some small errors to get a big saving in the efficiency metrics in return.",
    "This section provides an overview of our comprehensive experimental phase, describes the algorithm selected as the competitor for validating our analysis, and presents a discussion of the key results achieved.",
    "To compare and verify our results, we take advantage of a revised version of the algorithm originally proposed by Montresor et al. [16], which was designed for static graphs. The structure of this algorithm mirrors that of Algorithm 1, meaning each node monitors updates to its own coreness estimate and maintains an estimate of the coreness of its neighboring nodes. Montresor et al. provide a formal proof demonstrating that their method consistently converges to the accurate coreness value for every node in a graph [16]. This algorithm can be modified to accommodate the temporal scenario by recalculating completely whenever there is an epoch transition: each node discards all estimates about its neighbors and assigns its coreness equal to its degree. We use this adaptation to compute ground truth values for the coreness of nodes, and to show the amount of savings we can achieve by adopting our fine-tuned strategy instead of a direct translation of an existing algorithm to the temporal context.",
    "We implemented both algorithms (Algorithm 1 and the aforementioned competitor by Montresor et al. [16]) in the Rust programming language, and carried out our experiments on the following architecture: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz, 8 physical cores, 16 logical cores with 64 GB of RAM, and 16 MB of shared L3 cache. Our code is publicly available on GitHub4 . To simulate the distributed environment, we used two queues for gathering nodes and messages sent by the nodes, to dispatch them to the appropriate recipients. Initially, we gather the indices of nodes required to transmit a message as a vector. Subsequently, each node sends its message to a separate message queue, and ultimately, each message is sent to the appropriate recipient for processing. A node that receives a message and needs to send a new one will postpone its transmission until the next iteration of the algorithm. To streamline deployment and evaluation, our implementation includes a central entity called the Graph that verifies the convergence of the algorithm and the coreness computation of each node. However, we remark that Algorithm 1 is entirely decentralized and works correctly without an orchestrator.",
    "We run the experiments on a dataset of real-world temporal graphs obtained from the SNAP Repository [10] and Network Repository [17]. The dataset, summarized in in Table 1, offers a varying level of dynamism, i.e. how much and how fast a graph changes over time, that can be noticed by looking at the plots in Figs. 2(d) and 3(d), which show how much a graph changes between two consecutive epochs. For each graph, we only give the maximum number of distinct nodes that have been active at least once throughout the lifespan of the graph. For any given epoch, the number of nodes that are part of the graph, i.e., that have at least one incident edge, is upper-bounded by this value. The number of edges reported follows a similar rationale, representing the total count of edges present in the graph during at least one epoch. We manually chose the epoch length for each graph by grouping edges according to their timestamp, in a way such that each epoch is sufficiently populated with nodes and edges so that the results obtained are not trivial (e.g. nodes are not isolated and there is enough change in active edges for any two consecutive epochs). We run both algorithms on the whole dataset, collecting the following metrics:",
    "-Activated nodes: nodes that sent at least one message during the execution of the algorithms. -Number of iterations: number of iterations of the main loop of the algorithms needed at a certain epoch to terminate their execution. -Number of messages: the number of messages sent by all nodes for each iteration of the algorithms. -Errors: number of nodes that computed a different coreness value in Algorithm 1 with respect to the ones computed by our competitor.",
    "Different values for the memory size of each node were tested, spanning from a minimal size (1) to a larger size (10). Given space constraints, we present results solely for a memory size of 5, which represents a compromise between the extremes. Moreover, as we pointed out in Section 1, we tested different edge aggregation functions, namely intersection, union and union-2 (or half ), i.e., every edge must appear at least half of the memory size times (for a memory size of 5, half corresponds to 2, = ⌊5/2⌋).",
    "Table 2 summarizes the results we obtained for Algorithm 1, compared to our competitor, highlighting the ratio between the two. We can immediately notice that the ratio of both the activated nodes and the total messages is always well below 1, showing a big savings on these two critical measures. Another thing we notice is the average number of iterations performed by Algorithm 1 against the competitor: this is due to our strategy of delaying the action of sending an update to the next iteration, to reduce the error rate. Although this may appear as a step back with respect to the Montresor et al. strategy [16], it is important to note that despite this, the number of activated nodes and the total number of messages exchanged do not increase. Thus, the savings in resources are still consistent even if the number of iterations to reach convergence increases. Moreover, in our experiments, this number never exceeded twice the amount of the competitor. Fig. 2(c) shows the values of the number of iterations for the AS-733 dataset, where we can further verify this statement. We now turn to the error rate. Recall that we count one error for each node that, at the end of an execution of Algorithm 1, has a coreness value different from the one computed by our competitor algorithm. Table 2 shows the average number of errors per epoch, both in absolute and relative terms, relative to the number of nodes in the graph. We consistently obtained less than 1% of errors in every configuration for every dataset, proving we can achieve a significant speedup without losing too much accuracy. Additionally, in our experiments, we verified that all errors are always ±1 with respect to the correct value of coreness computed by our competitor. It is interesting to see how the algorithm reacts to different epoch lengths when the aggregation function and memory size are fixed. Indeed, there is basically no difference between the results for the Reddit dataset when the epoch length is enlarged to 14 days instead of 7. On the other hand, if we change the function and keep the same epoch length, things change drastically (e.g. Reddit dataset with intersection).",
    "Fig. 2 and Fig. 3 go more in depth on the statistics we gathered for two specific datasets and configurations, namely AS-733 with intersection as the edge aggregation function, and sx-mathoverflow with union. In particular, we plotted the percentage of activated nodes for our algorithm and our competitor by Montresor et al. [16], together with two measures of how much the corresponding graph has changed with respect to the previous epoch. We first computed the Jaccard similarity between the edge list of any two consecutive epochs and subtracted it from 1 to obtain a measure of how much the graph has changed from the perspective of the edges. This number is trivially equal to 1 for the first epoch of every graph.",
    "We also calculated the number of nodes that changed their coreness value with respect to the previous epoch: this number also includes those nodes who became isolated (i.e. have coreness equal to 0 or, equivalently, are not part of the graph anymore) on an epoch, hence the spikes in Fig. 2. Correctly, the number of activated nodes stays low even in the presence of such spikes, because the isolated nodes do not send any message, therefore, they cannot become active. On the other hand, we see that the trend of activated nodes in AS-733 (Fig. 2) follows the trend of how much the edges in the graph change, as high values of dissimilarity (pink line) correspond to higher values of activated nodes by Algorithm 1. This holds for our competitor too, but that algorithm is blind to changes in the graph 5 , as it recomputes everything from scratch each time.",
    "The experimental results suggest two main conclusions about our approach: 5 For the AS-733 dataset, there is a significant change in the graph in epochs 54-59. This is intrinsic to the dataset itself and not caused by our implementation. The possible reasons behind this sudden change are discussed in [5].",
    "1. Algorithm 1 significantly reduces the number of exchanged messages compared to the competitor solution. This translates into lower computational demand and enables the analysis of larger graphs than previously feasible. 2. Although our algorithm requires slightly more iterations to converge, it maintains a low level of node activation throughout. As a result, the majority of nodes remain idle during execution, minimizing overall resource consumption and increasing scalability despite the increased number of rounds.",
    "We presented a new decentralized algorithm for the maintenance of core decomposition in large temporal graphs, an important task for community detection and analysis in nowadays networks. We conducted an extensive experimental phase, demonstrating significant performance improvements compared to the direct translation of an existing algorithm [16] into the temporal scenario. These improvements are measured in terms of the total messages exchanged during the algorithm's execution and the number of graph nodes that send at least one message. While this strategy sometimes leads to small errors in the computed coreness values, we showed that these errors are (a) always at ±1 unit from the true value, and (b) extremely infrequent in our real-world dataset. Our findings pave the way for future work on this algorithm, to ensure its correctness in all cases while maintaining the same desirable performance.",
    "https://github.com/DavideR95/temporal_distributed_kcores"
  ],
  "references": [
    {
      "id": 1,
      "text": "Distributed k-core decomposition and maintenance in large dynamic graphs\n\t\t\n\t\t\tSabeurAridhi\n\t\t\n\t\t\n\t\t\tMartinBrugnara\n\t\t\n\t\t\n\t\t\tAlbertoMontresor\n\t\t\n\t\t\n\t\t\tYannisVelegrakis\n\t\t\n\t\t10.1145/2933267.2933299\n\t\n\t\n\t\tProceedings of the 10th ACM International Conference on Distributed and Event-based Systems\n\t\tthe 10th ACM International Conference on Distributed and Event-based Systems\n\t\t\n\t\t\tACM\n\t\t\t2016"
    },
    {
      "id": 2,
      "text": "Aggregate centrality measures for IoT-based coordination\n\t\t\n\t\t\tGiorgioAudrito\n\t\t\n\t\t\n\t\t\tDaniloPianini\n\t\t\n\t\t\n\t\t\tFerruccioDamiani\n\t\t\n\t\t\n\t\t\tMirkoViroli\n\t\t\n\t\t10.1016/j.scico.2020.102584\n\t\n\t\n\t\tScience of Computer Programming\n\t\tScience of Computer Programming\n\t\t0167-6423\n\t\t\n\t\t\t203\n\t\t\t102584\n\t\t\t2021\n\t\t\tElsevier BV"
    },
    {
      "id": 3,
      "text": "An O(m) algorithm for cores decomposition of networks\n\t\t\n\t\t\tVBatagelj\n\t\t\n\t\t\n\t\t\tMZaversnik\n\t\t\n\t\tarXiv preprint cs/0310049\n\t\t\n\t\t\t2003"
    },
    {
      "id": 4,
      "text": "Efficient application image management in the compute continuum: A vertex cover approach based on the think-like-a-vertex paradigm\n\t\t\n\t\t\tECarlini\n\t\t\n\t\t\n\t\t\tPDazzi\n\t\t\n\t\t\n\t\t\tAMakris\n\t\t\n\t\t\n\t\t\tMMordacchini\n\t\t\n\t\t\n\t\t\tTTheodoropoulos\n\t\t\n\t\t\n\t\t\tKTserpes\n\t\t\n\t\n\t\n\t\t2024 IEEE 17th Int. Conf. on Cloud Computing (CLOUD)\n\t\t\n\t\t\tIEEE\n\t\t\t2024"
    },
    {
      "id": 5,
      "text": "Are k-cores meaningful for temporal graph analysis?\n\t\t\n\t\t\tAlessioConte\n\t\t\t0000-0003-0770-2235\n\t\t\n\t\t\n\t\t\tDavideRucci\n\t\t\t0000-0003-1273-2770\n\t\t\n\t\t10.1145/3605098.3635959\n\t\n\t\n\t\tProceedings of the 39th ACM/SIGAPP Symposium on Applied Computing\n\t\tthe 39th ACM/SIGAPP Symposium on Applied ComputingNew York, NY, USA\n\t\t\n\t\t\tACM\n\t\t\t2024"
    },
    {
      "id": 6,
      "text": "Community detection in graphs\n\t\t\n\t\t\tSantoFortunato\n\t\t\n\t\t10.1016/j.physrep.2009.11.002\n\t\n\t\n\t\tPhysics Reports\n\t\tPhysics Reports\n\t\t0370-1573\n\t\t\n\t\t\t486\n\t\t\t3-5\n\t\t\t\n\t\t\t2010\n\t\t\tElsevier BV"
    },
    {
      "id": 7,
      "text": "Span-core Decomposition for Temporal Networks\n\t\t\n\t\t\tEdoardoGalimberti\n\t\t\n\t\t\n\t\t\tMartinoCiaperoni\n\t\t\n\t\t\n\t\t\tAlainBarrat\n\t\t\n\t\t\n\t\t\tFrancescoBonchi\n\t\t\n\t\t\n\t\t\tCiroCattuto\n\t\t\n\t\t\n\t\t\tFrancescoGullo\n\t\t\n\t\t10.1145/3418226\n\t\n\t\n\t\tACM Transactions on Knowledge Discovery from Data\n\t\tACM Trans. Knowl. Discov. Data\n\t\t1556-4681\n\t\t1556-472X\n\t\t\n\t\t\t15\n\t\t\t1\n\t\t\t\n\t\t\tdec 2020\n\t\t\tAssociation for Computing Machinery (ACM)"
    },
    {
      "id": 8,
      "text": "Evaluating Cooperation in Communities with the k-Core Structure\n\t\t\n\t\t\tChristosGiatsidis\n\t\t\n\t\t\n\t\t\tDimitriosMThilikos\n\t\t\n\t\t\n\t\t\tMichalisVazirgiannis\n\t\t\n\t\t10.1109/asonam.2011.65\n\t\n\t\n\t\t2011 International Conference on Advances in Social Networks Analysis and Mining\n\t\t\n\t\t\tIEEE\n\t\t\t2011"
    },
    {
      "id": 9,
      "text": "<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\" id=\"d1e1482\" altimg=\"si50.svg\"><mml:mi>k</mml:mi></mml:math>-core: Theories and applications\n\t\t\n\t\t\tYi-XiuKong\n\t\t\n\t\t\n\t\t\tGui-YuanShi\n\t\t\n\t\t\n\t\t\tRui-JieWu\n\t\t\n\t\t\n\t\t\tYi-ChengZhang\n\t\t\n\t\t10.1016/j.physrep.2019.10.004\n\t\n\t\n\t\tPhysics Reports\n\t\tPhysics Reports\n\t\t0370-1573\n\t\t\n\t\t\t832\n\t\t\t\n\t\t\t2019\n\t\t\tElsevier BV"
    },
    {
      "id": 10,
      "text": "JLeskovec\n\t\t\n\t\t\n\t\t\tAKrevl\n\t\t\n\t\t\n\t\tSNAP Datasets: Stanford large network dataset collection\n\t\t\n\t\t\tJune 2014"
    },
    {
      "id": 11,
      "text": "Persistent community search in temporal networks\n\t\t\n\t\t\tR.-HLi\n\t\t\n\t\t\n\t\t\tJSu\n\t\t\n\t\t\n\t\t\tLQin\n\t\t\n\t\t\n\t\t\tJXYu\n\t\t\n\t\t\n\t\t\tQDai\n\t\t\n\t\n\t\n\t\tIEEE Int. Conf. on Data Engineering\n\t\t\n\t\t\t2018"
    },
    {
      "id": 12,
      "text": "Incremental Algorithms of the Core Maintenance Problem on Edge-Weighted Graphs\n\t\t\n\t\t\tBinLiu\n\t\t\t0000-0002-8958-3999\n\t\t\n\t\t\n\t\t\tFeitengZhang\n\t\t\t0000-0003-1803-5909\n\t\t\n\t\t10.1109/access.2020.2985327\n\t\n\t\n\t\tIEEE Access\n\t\tIEEE Access\n\t\t2169-3536\n\t\t\n\t\t\t8\n\t\t\t\n\t\t\t2020\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    },
    {
      "id": 13,
      "text": "Fast Connected Components Computation in Large Graphs by Vertex Pruning\n\t\t\n\t\t\tAlessandroLulli\n\t\t\n\t\t\n\t\t\tEmanueleCarlini\n\t\t\n\t\t\n\t\t\tPatrizioDazzi\n\t\t\n\t\t\n\t\t\tClaudioLucchese\n\t\t\n\t\t\n\t\t\tLauraRicci\n\t\t\n\t\t10.1109/tpds.2016.2591038\n\t\n\t\n\t\tIEEE Transactions on Parallel and Distributed Systems\n\t\tIEEE Trans. Parallel Distrib. Syst.\n\t\t1045-9219\n\t\t\n\t\t\t28\n\t\t\t3\n\t\t\t\n\t\t\t2017\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    },
    {
      "id": 14,
      "text": "The core decomposition of networks: theory, algorithms and applications\n\t\t\n\t\t\tFragkiskosDMalliaros\n\t\t\n\t\t\n\t\t\tChristosGiatsidis\n\t\t\n\t\t\n\t\t\tApostolosNPapadopoulos\n\t\t\t0000-0002-6172-354X\n\t\t\n\t\t\n\t\t\tMichalisVazirgiannis\n\t\t\n\t\t10.1007/s00778-019-00587-4\n\t\n\t\n\t\tThe VLDB Journal\n\t\tThe VLDB Journal\n\t\t1066-8888\n\t\t0949-877X\n\t\t\n\t\t\t29\n\t\t\t1\n\t\t\t\n\t\t\tJan 2020\n\t\t\tSpringer Science and Business Media LLC"
    },
    {
      "id": 15,
      "text": "The core decomposition of networks: theory, algorithms and applications\n\t\t\n\t\t\tFragkiskosDMalliaros\n\t\t\n\t\t\n\t\t\tChristosGiatsidis\n\t\t\n\t\t\n\t\t\tApostolosNPapadopoulos\n\t\t\t0000-0002-6172-354X\n\t\t\n\t\t\n\t\t\tMichalisVazirgiannis\n\t\t\n\t\t10.1007/s00778-019-00587-4\n\t\n\t\n\t\tThe VLDB Journal\n\t\tThe VLDB Journal\n\t\t1066-8888\n\t\t0949-877X\n\t\t\n\t\t\t29\n\t\t\t1\n\t\t\t\n\t\t\t2020\n\t\t\tSpringer Science and Business Media LLC"
    },
    {
      "id": 16,
      "text": "Distributed k-Core Decomposition\n\t\t\n\t\t\tAlbertoMontresor\n\t\t\n\t\t\n\t\t\tFrancescoDe Pellegrini\n\t\t\n\t\t\n\t\t\tDanieleMiorandi\n\t\t\n\t\t10.1109/tpds.2012.124\n\t\n\t\n\t\tIEEE Transactions on Parallel and Distributed Systems\n\t\tIEEE Trans. Parallel Distrib. Syst.\n\t\t1045-9219\n\t\t\n\t\t\t24\n\t\t\t2\n\t\t\t\n\t\t\tFeb. 2013\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    },
    {
      "id": 17,
      "text": "The Network Data Repository with Interactive Graph Analytics and Visualization\n\t\t\n\t\t\tRyanRossi\n\t\t\n\t\t\n\t\t\tNesreenAhmed\n\t\t\n\t\t10.1609/aaai.v29i1.9277\n\t\n\t\n\t\tProceedings of the AAAI Conference on Artificial Intelligence\n\t\tAAAI\n\t\t2159-5399\n\t\t2374-3468\n\t\t\n\t\t\t29\n\t\t\t1\n\t\t\t2015\n\t\t\tAssociation for the Advancement of Artificial Intelligence (AAAI)"
    },
    {
      "id": 18,
      "text": "Network structure and minimum degree\n\t\t\n\t\t\tStephenBSeidman\n\t\t\n\t\t10.1016/0378-8733(83)90028-x\n\t\n\t\n\t\tSocial Networks\n\t\tSocial Networks\n\t\t0378-8733\n\t\t\n\t\t\t5\n\t\t\t3\n\t\t\t\n\t\t\t1983\n\t\t\tElsevier BV"
    },
    {
      "id": 19,
      "text": "CoreScope: Graph Mining Using k-Core Analysis — Patterns, Anomalies and Algorithms\n\t\t\n\t\t\tKijungShin\n\t\t\n\t\t\n\t\t\tTinaEliassi-Rad\n\t\t\n\t\t\n\t\t\tChristosFaloutsos\n\t\t\n\t\t10.1109/icdm.2016.0058\n\t\n\t\n\t\t2016 IEEE 16th International Conference on Data Mining (ICDM)\n\t\t\n\t\t\tIEEE\n\t\t\t2016"
    },
    {
      "id": 20,
      "text": "Distributed Detecting of Critical Nodes for Maximization of Connected Components in Wireless Multi-hop Networks\n\t\t\n\t\t\tOnurUgurlu\n\t\t\t0000-0003-2743-5939\n\t\t\n\t\t\n\t\t\tNusinAkram\n\t\t\n\t\t\n\t\t\tYesimAygul\n\t\t\t0000-0003-0605-9604\n\t\t\n\t\t\n\t\t\tVahidKhalilpourAkram\n\t\t\t0000-0002-4082-6419\n\t\t\n\t\t\n\t\t\tOrhanDagdeviren\n\t\t\t0000-0001-8789-5086\n\t\t\n\t\t10.1016/j.adhoc.2024.103744\n\t\n\t\n\t\tAd Hoc Networks\n\t\tAd Hoc Networks\n\t\t1570-8705\n\t\t\n\t\t\t169\n\t\t\t103744\n\t\t\t2025\n\t\t\tElsevier BV"
    },
    {
      "id": 21,
      "text": "Systematic Review on Decentralised Artificial Intelligence and Its Applications\n\t\t\n\t\t\tMariyaVincent\n\t\t\n\t\t\n\t\t\tAnjuEGeorge\n\t\t\n\t\t\n\t\t\tNJayapandian\n\t\t\n\t\t10.1109/icidca56705.2023.10100017\n\t\n\t\n\t\t2023 International Conference on Innovative Data Communication Technologies and Application (ICIDCA)\n\t\t\n\t\t\tIEEE\n\t\t\t2023"
    },
    {
      "id": 22,
      "text": "Efficient Distributed Approaches to Core Maintenance on Large Dynamic Graphs\n\t\t\n\t\t\tTongfengWeng\n\t\t\t0000-0002-8463-6334\n\t\t\n\t\t\n\t\t\tXuZhou\n\t\t\t0000-0002-0764-0620\n\t\t\n\t\t\n\t\t\tKenliLi\n\t\t\t0000-0002-2635-7716\n\t\t\n\t\t\n\t\t\tPengPeng\n\t\t\t0000-0002-8095-8061\n\t\t\n\t\t\n\t\t\tKeqinLi\n\t\t\t0000-0001-5224-4048\n\t\t\n\t\t10.1109/tpds.2021.3090759\n\t\n\t\n\t\tIEEE Transactions on Parallel and Distributed Systems\n\t\tIEEE Trans. Parallel Distrib. Syst.\n\t\t1045-9219\n\t\t2161-9883\n\t\t\n\t\t\t33\n\t\t\t1\n\t\t\t\n\t\t\t2022\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    },
    {
      "id": 23,
      "text": "Core decomposition in large temporal graphs\n\t\t\n\t\t\tHuanhuanWu\n\t\t\n\t\t\n\t\t\tJamesCheng\n\t\t\n\t\t\n\t\t\tYiLu\n\t\t\n\t\t\n\t\t\tYipingKe\n\t\t\n\t\t\n\t\t\tYuzhenHuang\n\t\t\n\t\t\n\t\t\tDaYan\n\t\t\n\t\t\n\t\t\tHejunWu\n\t\t\n\t\t10.1109/bigdata.2015.7363809\n\t\n\t\n\t\t2015 IEEE International Conference on Big Data (Big Data)\n\t\t\n\t\t\tIEEE\n\t\t\t2015"
    },
    {
      "id": 24,
      "text": "Decentralized and Distributed Learning for AIoT: A Comprehensive Review, Emerging Challenges, and Opportunities\n\t\t\n\t\t\tHanyueXu\n\t\t\n\t\t\n\t\t\tKahPhooiSeng\n\t\t\t0000-0002-8071-9044\n\t\t\n\t\t\n\t\t\tLiMinnAng\n\t\t\t0000-0002-2402-7529\n\t\t\n\t\t\n\t\t\tJeremySmith\n\t\t\n\t\t10.1109/access.2024.3422211\n\t\n\t\n\t\tIEEE Access\n\t\tIEEE Access\n\t\t2169-3536\n\t\t\n\t\t\t12\n\t\t\t\n\t\t\t2024\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    },
    {
      "id": 25,
      "text": "Scalable Time-Range <i>k</i> -Core Query on Temporal Graphs\n\t\t\n\t\t\tJunyongYang\n\t\t\n\t\t\n\t\t\tMingZhong\n\t\t\n\t\t\n\t\t\tYuanyuanZhu\n\t\t\n\t\t\n\t\t\tTieyunQian\n\t\t\n\t\t\n\t\t\tMengchiLiu\n\t\t\n\t\t\n\t\t\tJeffreyXuYu\n\t\t\n\t\t10.14778/3579075.3579089\n\t\n\t\n\t\tProceedings of the VLDB Endowment\n\t\tProc. VLDB Endow.\n\t\t2150-8097\n\t\t\n\t\t\t16\n\t\t\t5\n\t\t\t\n\t\t\tjan 2023\n\t\t\tAssociation for Computing Machinery (ACM)"
    },
    {
      "id": 26,
      "text": "Breadth-first search tree integrated vertex cover algorithms for link monitoring and routing in wireless sensor networks\n\t\t\n\t\t\tYasinYigit\n\t\t\t0000-0001-5257-9382\n\t\t\n\t\t\n\t\t\tVahidKhalilpourAkram\n\t\t\t0000-0002-4082-6419\n\t\t\n\t\t\n\t\t\tOrhanDagdeviren\n\t\t\t0000-0001-8789-5086\n\t\t\n\t\t10.1016/j.comnet.2021.108144\n\t\n\t\n\t\tComputer Networks\n\t\tComputer Networks\n\t\t1389-1286\n\t\t\n\t\t\t194\n\t\t\t108144\n\t\t\t2021\n\t\t\tElsevier BV"
    },
    {
      "id": 27,
      "text": "Efficient State Sharding in Blockchain via Density-based Graph Partitioning\n\t\t\n\t\t\tBoYin\n\t\t\t0000-0002-0281-5970\n\t\t\n\t\t\n\t\t\tPengZhang\n\t\t\t0009-0001-5911-4796\n\t\t\n\t\t\n\t\t\tTingxuanChen\n\t\t\t0009-0000-0621-0699\n\t\t\n\t\t10.1145/3697840\n\t\n\t\n\t\tACM Transactions on the Web\n\t\tACM Trans. Web\n\t\t1559-1131\n\t\t1559-114X\n\t\t\n\t\t\t19\n\t\t\t1\n\t\t\t\n\t\t\tDec. 2024\n\t\t\tAssociation for Computing Machinery (ACM)"
    },
    {
      "id": 28,
      "text": "Fast Core Maintenance in Dynamic Graphs\n\t\t\n\t\t\tDongxiaoYu\n\t\t\t0000-0001-6835-5981\n\t\t\n\t\t\n\t\t\tNaWang\n\t\t\n\t\t\n\t\t\tQiLuo\n\t\t\t0000-0002-1018-8727\n\t\t\n\t\t\n\t\t\tFengLi\n\t\t\n\t\t\n\t\t\tJiguoYu\n\t\t\t0000-0001-6451-1158\n\t\t\n\t\t\n\t\t\tXiuzhenCheng\n\t\t\t0000-0001-5912-4647\n\t\t\n\t\t\n\t\t\tZhipengCai\n\t\t\t0000-0001-6017-975X\n\t\t\n\t\t10.1109/tcss.2021.3064836\n\t\n\t\n\t\tIEEE Transactions on Computational Social Systems\n\t\tIEEE Trans. Comput. Soc. Syst.\n\t\t2373-7476\n\t\t\n\t\t\t9\n\t\t\t3\n\t\t\t\n\t\t\t2022\n\t\t\tInstitute of Electrical and Electronics Engineers (IEEE)"
    }
  ],
  "formulas": [
    {
      "id": "FORMULA_1",
      "raw": "2 changed ← false 3 core ← d(u) 4 foreach v ∈ N (u) do est[v] ← ∞ 5 on epoch change do 6 oldCore ← core 7 if there is at least one new neighbor v then 8 core ← d(u) 9 changed ← true est[v] ← ∞ else if a neighbor is lost then core ← computeCoreness (est,u,core) if oldCore ̸ = core then changed ← true on receive ⟨v, k⟩ do est[v] ← k t ← computeCoreness (est,u,core) if t ̸ = core then if t < core then wait one iteration before sending update core ← t changed ← true repeat if changed then send ⟨u, core⟩ to N (u) changed ← false until convergence Function ComputeCoreness(est, u, k) foreach e ∈ est[] do if e < ∞ then if e < d(u) then count[e] ← count[e] + 1 else count[d(u)] ← count[d(u)] + 1 else return min{core, d(u)} total ← 0 for i = count.length down to 0 do total ← total + count[i] if total ≥ i then return i return d(u)"
    },
    {
      "id": "FORMULA_2",
      "raw": "E τ = {(u, v, t) | u, v ∈ V, 1 ≤ t ≤ τ },"
    },
    {
      "id": "FORMULA_3",
      "raw": "G[K] = (K, E K = {(u, v) ∈ E | u, v ∈ K})."
    },
    {
      "id": "FORMULA_4",
      "raw": "E τ × [a, b] → E τ that, given a time interval [a, b]"
    },
    {
      "id": "FORMULA_5",
      "raw": "t of v ∈ V is d t (v) = |N t (v)|"
    }
  ]
}